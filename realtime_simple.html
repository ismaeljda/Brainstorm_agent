<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Assistant Vocal - Simple & Rapide</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: system-ui, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            max-width: 600px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        h1 { text-align: center; color: #333; margin-bottom: 30px; }
        .status {
            text-align: center;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-weight: 600;
        }
        .status.connected { background: #d4edda; color: #155724; }
        .status.disconnected { background: #f8d7da; color: #721c24; }
        .status.speaking { background: #fff3cd; color: #856404; }
        button {
            display: block;
            width: 100%;
            padding: 15px;
            margin-bottom: 20px;
            border: none;
            border-radius: 10px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }
        .btn-connect { background: #667eea; color: white; }
        .btn-connect:hover { background: #5568d3; }
        .btn-disconnect { background: #f56565; color: white; display: none; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        .transcript {
            background: #f7fafc;
            border-radius: 10px;
            padding: 20px;
            min-height: 300px;
            max-height: 400px;
            overflow-y: auto;
        }
        .message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 8px;
            animation: fadeIn 0.3s;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .message.user { background: #e6f2ff; border-left: 3px solid #667eea; }
        .message.assistant { background: #f0fdf4; border-left: 3px solid #10b981; }
        .msg-label {
            font-size: 0.75rem;
            font-weight: 700;
            text-transform: uppercase;
            color: #666;
            margin-bottom: 5px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Assistant Vocal Realtime</h1>

        <div class="status disconnected" id="status">üî¥ D√©connect√©</div>

        <button class="btn-connect" id="connectBtn">Connecter</button>
        <button class="btn-disconnect" id="disconnectBtn">D√©connecter</button>

        <div class="transcript" id="transcript">
            <div style="text-align: center; color: #999; padding: 60px 20px;">
                Clique sur "Connecter" pour commencer...
            </div>
        </div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let audioWorkletNode = null;
        let currentAssistantMessage = '';

        const status = document.getElementById('status');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const transcript = document.getElementById('transcript');

        function updateStatus(text, className) {
            status.textContent = text;
            status.className = 'status ' + className;
        }

        function addMessage(role, content) {
            if (transcript.querySelector('[style*="center"]')) {
                transcript.innerHTML = '';
            }

            const msg = document.createElement('div');
            msg.className = 'message ' + role;
            msg.innerHTML = `
                <div class="msg-label">${role === 'user' ? 'üë§ Vous' : 'ü§ñ Assistant'}</div>
                <div class="msg-content">${content}</div>
            `;
            transcript.appendChild(msg);
            transcript.scrollTop = transcript.scrollHeight;
            return msg;
        }

        async function connect() {
            try {
                updateStatus('üîÑ Connexion...', 'speaking');
                connectBtn.disabled = true;

                // Get token
                const tokenRes = await fetch('http://localhost:5000/api/token');
                if (!tokenRes.ok) throw new Error('Failed to get token');

                const { token } = await tokenRes.json();
                console.log('‚úÖ Token received');

                // Get microphone (let browser use native sample rate)
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                console.log('üé§ Microphone acquired');

                // Connect WebSocket
                const url = `wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17`;
                ws = new WebSocket(url, [
                    'realtime',
                    `openai-insecure-api-key.${token}`,
                    'openai-beta.realtime-v1'
                ]);

                ws.onopen = async () => {
                    console.log('‚úÖ WebSocket connected');

                    // Configure session
                    ws.send(JSON.stringify({
                        type: 'session.update',
                        session: {
                            modalities: ['text', 'audio'],
                            instructions: `Tu es un assistant de brainstorming pour entrepreneurs.

Aide les entrepreneurs √†:
- Clarifier leurs id√©es
- Identifier le market fit
- D√©finir les prochaines √©tapes

Style:
- Une question cibl√©e √† la fois
- R√©ponses COURTES (2-3 phrases max)
- Collaboratif et encourageant`,
                            voice: 'alloy',
                            input_audio_format: 'pcm16',
                            output_audio_format: 'pcm16',
                            turn_detection: {
                                type: 'server_vad',
                                threshold: 0.5,
                                silence_duration_ms: 700
                            },
                            input_audio_transcription: {
                                model: 'whisper-1'
                            }
                        }
                    }));

                    // Start audio streaming
                    await startAudioStreaming();

                    updateStatus('üü¢ Connect√© - Parle!', 'connected');
                    connectBtn.style.display = 'none';
                    disconnectBtn.style.display = 'block';
                };

                ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);

                    switch (data.type) {
                        case 'conversation.item.input_audio_transcription.completed':
                            addMessage('user', data.transcript);
                            break;

                        case 'response.audio_transcript.delta':
                            currentAssistantMessage += data.delta;
                            break;

                        case 'response.audio_transcript.done':
                            if (currentAssistantMessage) {
                                addMessage('assistant', currentAssistantMessage);
                                currentAssistantMessage = '';
                            }
                            break;

                        case 'response.audio.delta':
                            playAudioChunk(data.delta);
                            break;

                        case 'error':
                            console.error('Error:', data.error);
                            break;
                    }
                };

                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    disconnect();
                };

                ws.onclose = () => {
                    console.log('WebSocket closed');
                    disconnect();
                };

            } catch (error) {
                console.error('Connection error:', error);
                alert('Erreur: ' + error.message);
                updateStatus('‚ùå Erreur', 'disconnected');
                connectBtn.disabled = false;
            }
        }

        async function startAudioStreaming() {
            // Create audio context with native sample rate (will be resampled)
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            console.log('üéµ Audio context created, sampleRate:', audioContext.sampleRate);

            const source = audioContext.createMediaStreamSource(mediaStream);

            // Use ScriptProcessor (deprecated but widely supported)
            const processor = audioContext.createScriptProcessor(2048, 1, 1);

            let audioChunkCount = 0;
            const targetSampleRate = 24000;
            const sourceSampleRate = audioContext.sampleRate;
            const sampleRateRatio = sourceSampleRate / targetSampleRate;

            console.log(`üîÑ Resampling: ${sourceSampleRate}Hz ‚Üí ${targetSampleRate}Hz (ratio: ${sampleRateRatio.toFixed(2)})`);

            processor.onaudioprocess = (e) => {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    const inputData = e.inputBuffer.getChannelData(0);

                    // Downsample from sourceSampleRate to 24000Hz
                    const outputLength = Math.floor(inputData.length / sampleRateRatio);
                    const resampled = new Float32Array(outputLength);

                    for (let i = 0; i < outputLength; i++) {
                        const sourceIndex = Math.floor(i * sampleRateRatio);
                        resampled[i] = inputData[sourceIndex];
                    }

                    // Convert Float32 to Int16 PCM
                    const int16 = new Int16Array(resampled.length);
                    for (let i = 0; i < resampled.length; i++) {
                        const s = Math.max(-1, Math.min(1, resampled[i]));
                        int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // Convert to base64
                    const bytes = new Uint8Array(int16.buffer);
                    let binary = '';
                    for (let i = 0; i < bytes.length; i++) {
                        binary += String.fromCharCode(bytes[i]);
                    }
                    const base64 = btoa(binary);

                    // Send to OpenAI
                    ws.send(JSON.stringify({
                        type: 'input_audio_buffer.append',
                        audio: base64
                    }));

                    // Log every 100 chunks to avoid spam
                    audioChunkCount++;
                    if (audioChunkCount % 100 === 0) {
                        console.log(`üì§ Sent ${audioChunkCount} audio chunks (${base64.length} bytes each)`);
                    }
                }
            };

            source.connect(processor);
            processor.connect(audioContext.destination);
        }

        // Audio playback queue
        let audioQueue = [];
        let isPlaying = false;

        function playAudioChunk(base64Audio) {
            audioQueue.push(base64Audio);
            if (!isPlaying) playNextChunk();
        }

        function playNextChunk() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }

            isPlaying = true;
            const base64 = audioQueue.shift();

            // Decode base64 to ArrayBuffer
            const binary = atob(base64);
            const bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) {
                bytes[i] = binary.charCodeAt(i);
            }

            // Convert Int16 PCM to Float32
            const int16 = new Int16Array(bytes.buffer);
            const float32 = new Float32Array(int16.length);
            for (let i = 0; i < int16.length; i++) {
                float32[i] = int16[i] / 32768.0;
            }

            // Create and play audio buffer
            const audioBuffer = audioContext.createBuffer(1, float32.length, 24000);
            audioBuffer.getChannelData(0).set(float32);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.onended = () => playNextChunk();
            source.start();
        }

        function disconnect() {
            if (ws) {
                ws.close();
                ws = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(t => t.stop());
                mediaStream = null;
            }
            updateStatus('üî¥ D√©connect√©', 'disconnected');
            connectBtn.style.display = 'block';
            connectBtn.disabled = false;
            disconnectBtn.style.display = 'none';
        }

        connectBtn.addEventListener('click', connect);
        disconnectBtn.addEventListener('click', disconnect);
    </script>
</body>
</html>

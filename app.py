"""
Application web Flask pour l'interface vocale interactive.
Permet de parler via le micro du navigateur et d'Ã©couter la rÃ©ponse.
"""

import os
import io
import tempfile
import requests
from flask import Flask, render_template, request, jsonify, send_file
from flask_cors import CORS
from dotenv import load_dotenv
from openai import OpenAI
from elevenlabs.client import ElevenLabs
import speech_recognition as sr
from pydub import AudioSegment

# Charger les variables d'environnement
load_dotenv("src/.env")

# Initialiser Flask
app = Flask(__name__)
CORS(app)

# Initialiser les clients
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
elevenlabs_client = ElevenLabs(api_key=os.getenv("ELEVENLABS_API_KEY"))
recognizer = sr.Recognizer()

# Configuration
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID", "21m00Tcm4TlvDq8ikWAM")

# ElevenLabs voice IDs for multi-agent system
AGENT_VOICES = {
    'ceo': '21m00Tcm4TlvDq8ikWAM',      # Rachel - Professional female
    'marketing': 'EXAVITQu4vr4xnSDxMaL',  # Bella - Enthusiastic female
    'tech': 'TxGEqnHWrfWFTfGW9XjX',      # Josh - Clear male
    'finance': 'pNInz6obpgDQGcFmaJgB',    # Adam - Articulate male
}


@app.route('/')
def index():
    """Page principale."""
    return render_template('index.html')


@app.route('/meeting')
def meeting_room():
    """Interface de meeting room avec multi-agents vocaux."""
    return render_template('meeting_room.html')


@app.route('/api/token', methods=['GET'])
def get_token():
    """
    GÃ©nÃ¨re un token Ã©phÃ©mÃ¨re pour l'API OpenAI Realtime.
    Ce token permet au frontend de se connecter directement au WebSocket OpenAI
    sans exposer la clÃ© API principale.
    """
    try:
        print("ğŸ”‘ GÃ©nÃ©ration d'un token Ã©phÃ©mÃ¨re pour OpenAI Realtime API...")

        response = requests.post(
            'https://api.openai.com/v1/realtime/sessions',
            headers={
                'Authorization': f'Bearer {os.getenv("OPENAI_API_KEY")}',
                'Content-Type': 'application/json'
            },
            json={
                'model': 'gpt-4o-realtime-preview-2024-12-17',
                'voice': 'alloy'
            }
        )

        if response.status_code != 200:
            print(f"âŒ Erreur API OpenAI: {response.status_code} - {response.text}")
            return jsonify({'error': 'Failed to generate token'}), 500

        data = response.json()
        token = data['client_secret']['value']
        expires_at = data['client_secret']['expires_at']

        print(f"âœ… Token gÃ©nÃ©rÃ© (expire: {expires_at})")

        return jsonify({
            'token': token,
            'expires_at': expires_at
        })

    except Exception as e:
        print(f"âŒ Erreur lors de la gÃ©nÃ©ration du token: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/transcribe', methods=['POST'])
def transcribe_audio():
    """
    Transcrit l'audio envoyÃ© depuis le navigateur.
    Whisper accepte directement WebM, pas besoin de conversion.
    """
    temp_path = None

    try:
        # VÃ©rifier qu'un fichier audio a Ã©tÃ© envoyÃ©
        if 'audio' not in request.files:
            return jsonify({'error': 'Aucun fichier audio fourni'}), 400

        audio_file = request.files['audio']

        # Sauvegarder le fichier temporairement
        # Whisper API accepte plusieurs formats dont webm, mp3, mp4, mpeg, mpga, m4a, wav
        # Utiliser .wav car c'est ce que le frontend envoie aprÃ¨s conversion
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:
            audio_file.save(temp_audio.name)
            temp_path = temp_audio.name

        print(f"ğŸ“¦ Fichier reÃ§u: {os.path.getsize(temp_path)} bytes")

        # Transcrire avec Whisper (OpenAI)
        # Whisper accepte directement le format WebM
        print("ğŸ¤ Envoi Ã  Whisper...")
        with open(temp_path, 'rb') as audio_file_obj:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file_obj,
                language="fr"
            )

        text = transcript.text
        print(f"ğŸ“ Transcription: {text}")

        return jsonify({
            'success': True,
            'text': text
        })

    except Exception as e:
        print(f"âŒ Erreur de transcription: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

    finally:
        # Nettoyer le fichier temporaire
        if temp_path and os.path.exists(temp_path):
            os.unlink(temp_path)


@app.route('/api/chat', methods=['POST'])
def chat_with_agent():
    """
    Agent conversationnel simple - rÃ©pond en une seule fois (pas de streaming).
    """
    try:
        data = request.json
        user_message = data.get('text', '')
        conversation_history = data.get('history', [])

        if not user_message:
            return jsonify({'error': 'Aucun message fourni'}), 400

        print(f"ğŸ’¬ Message utilisateur: '{user_message}'")

        # Construire l'historique de conversation
        messages = [
            {
                "role": "system",
                "content": """Tu es un assistant de brainstorming intelligent et crÃ©atif.
Tu aides les consultants indÃ©pendants Ã  dÃ©velopper leurs idÃ©es de business.
Tu poses des questions pertinentes, proposes des idÃ©es innovantes et donnes des conseils stratÃ©giques.
RÃ©ponds toujours en franÃ§ais de maniÃ¨re claire, concise et professionnelle.
Sois enthousiaste et encourageant.
Fais des phrases courtes et claires."""
            }
        ]

        # Ajouter l'historique de conversation
        messages.extend(conversation_history)

        # Ajouter le nouveau message de l'utilisateur
        messages.append({
            "role": "user",
            "content": user_message
        })

        # GÃ©nÃ©rer la rÃ©ponse avec GPT (sans streaming)
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=200
        )

        agent_response = response.choices[0].message.content.strip()
        print(f"âœ… RÃ©ponse agent: '{agent_response}'")

        return jsonify({
            'success': True,
            'response': agent_response
        })

    except Exception as e:
        print(f"âŒ Erreur agent: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/chat_stream', methods=['POST'])
def chat_with_agent_stream():
    """
    Agent conversationnel avec streaming - gÃ©nÃ¨re et envoie le texte progressivement.
    """
    try:
        data = request.json
        user_message = data.get('text', '')
        conversation_history = data.get('history', [])

        if not user_message:
            return jsonify({'error': 'Aucun message fourni'}), 400

        print(f"ğŸ’¬ Message utilisateur: '{user_message}'")

        # Construire l'historique de conversation
        messages = [
            {
                "role": "system",
                "content": """Tu es un assistant de brainstorming intelligent et crÃ©atif.
Tu aides les consultants indÃ©pendants Ã  dÃ©velopper leurs idÃ©es de business.
Tu poses des questions pertinentes, proposes des idÃ©es innovantes et donnes des conseils stratÃ©giques.
RÃ©ponds toujours en franÃ§ais de maniÃ¨re claire, concise et professionnelle.
Sois enthousiaste et encourageant.
Fais des phrases courtes et claires."""
            }
        ]

        # Ajouter l'historique de conversation
        messages.extend(conversation_history)

        # Ajouter le nouveau message de l'utilisateur
        messages.append({
            "role": "user",
            "content": user_message
        })

        def generate():
            """GÃ©nÃ©rateur pour le streaming SSE (Server-Sent Events)"""
            try:
                # GÃ©nÃ©rer la rÃ©ponse avec GPT en streaming
                stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    temperature=0.7,
                    max_tokens=200,
                    stream=True  # Activer le streaming
                )

                full_response = ""
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        # Envoyer chaque morceau au client
                        yield f"data: {content}\n\n"

                # Envoyer le signal de fin
                yield "data: [DONE]\n\n"

                print(f"âœ… RÃ©ponse complÃ¨te: '{full_response}'")

            except Exception as e:
                print(f"âŒ Erreur streaming: {e}")
                yield f"data: [ERROR]: {str(e)}\n\n"

        return app.response_class(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        print(f"âŒ Erreur agent: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/speak', methods=['POST'])
def text_to_speech():
    """
    Convertit le texte en audio avec ElevenLabs et renvoie le fichier audio.
    Supporte les multi-voix pour le systÃ¨me d'agents.
    """
    try:
        data = request.json
        text = data.get('text', '')
        agent_id = data.get('agent', None)  # Optionnel: pour multi-agent

        if not text:
            return jsonify({'error': 'Aucun texte fourni'}), 400

        # Choisir la voix: agent spÃ©cifique ou voix par dÃ©faut
        if agent_id and agent_id in AGENT_VOICES:
            voice_id = AGENT_VOICES[agent_id]
            print(f"ğŸµ GÃ©nÃ©ration audio pour agent '{agent_id}' ({voice_id}): '{text[:50]}...'")
        else:
            voice_id = ELEVENLABS_VOICE_ID
            print(f"ğŸ”Š GÃ©nÃ©ration audio pour: '{text[:50]}...'")

        # GÃ©nÃ©rer l'audio avec ElevenLabs
        audio_generator = elevenlabs_client.text_to_speech.convert(
            voice_id=voice_id,
            text=text,
            model_id="eleven_multilingual_v2"
        )

        # Convertir en bytes
        audio_bytes = b"".join(audio_generator)

        print(f"âœ… Audio gÃ©nÃ©rÃ©: {len(audio_bytes)} bytes")

        # Retourner l'audio
        return send_file(
            io.BytesIO(audio_bytes),
            mimetype='audio/mpeg',
            as_attachment=False
        )

    except Exception as e:
        print(f"âŒ Erreur de synthÃ¨se vocale: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/chat_and_speak_stream', methods=['POST'])
def chat_and_speak_stream():
    """
    Streaming intelligent: GPT gÃ©nÃ¨re phrase par phrase, chaque phrase est convertie en audio.
    Format de sortie: Server-Sent Events avec texte ET audio encodÃ© en base64.
    """
    try:
        import json
        import base64
        import re

        data = request.json
        user_message = data.get('text', '')
        conversation_history = data.get('history', [])

        if not user_message:
            return jsonify({'error': 'Aucun message fourni'}), 400

        print(f"ğŸ’¬ Message utilisateur: '{user_message}'")

        # Construire l'historique de conversation
        messages = [
            {
                "role": "system",
                "content": """Tu es un assistant de brainstorming intelligent et crÃ©atif.
Tu aides les consultants indÃ©pendants Ã  dÃ©velopper leurs idÃ©es de business.
Tu poses des questions pertinentes, proposes des idÃ©es innovantes et donnes des conseils stratÃ©giques.
RÃ©ponds toujours en franÃ§ais de maniÃ¨re claire, concise et professionnelle.
Sois enthousiaste et encourageant.
Fais des phrases courtes et claires."""
            }
        ]
        messages.extend(conversation_history)
        messages.append({"role": "user", "content": user_message})

        def generate():
            """GÃ©nÃ©rateur qui stream texte + audio phrase par phrase"""
            try:
                # Streamer GPT
                stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    temperature=0.7,
                    max_tokens=200,
                    stream=True
                )

                buffer = ""
                sentence_buffer = []  # Buffer pour accumuler des phrases
                sentence_count = 0
                SENTENCES_PER_CHUNK = 2  # Envoyer par blocs de 2 phrases (plus rÃ©actif)

                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        buffer += content

                        # Envoyer le texte immÃ©diatement pour l'affichage
                        yield f"data: {json.dumps({'type': 'text', 'content': content})}\n\n"

                        # DÃ©tecter les fins de phrases (plus flexible avec ponctuation)
                        sentences = re.split(r'([.!?]+\s*)', buffer)

                        # Si on a au moins une phrase complÃ¨te
                        if len(sentences) > 2:
                            # RÃ©cupÃ©rer toutes les phrases complÃ¨tes
                            complete_sentences = ''.join(sentences[:-1])
                            buffer = sentences[-1]  # Garder le reste dans le buffer

                            if complete_sentences.strip():
                                sentence_buffer.append(complete_sentences.strip())
                                sentence_count += 1

                                print(f"âœ… Phrase #{sentence_count} dÃ©tectÃ©e: '{complete_sentences.strip()[:50]}...'")

                                # Envoyer l'audio par blocs de 2 phrases OU immÃ©diatement si dÃ©jÃ  beaucoup de texte
                                if len(sentence_buffer) >= SENTENCES_PER_CHUNK:
                                    text_chunk = ' '.join(sentence_buffer)
                                    sentence_buffer = []  # Vider le buffer

                                    print(f"ğŸµ GÃ©nÃ©ration audio ({len(sentence_buffer) + SENTENCES_PER_CHUNK} phrases): '{text_chunk[:60]}...'")

                                    # GÃ©nÃ©rer l'audio pour ce bloc SANS ATTENDRE
                                    try:
                                        audio_generator = elevenlabs_client.text_to_speech.convert(
                                            voice_id=ELEVENLABS_VOICE_ID,
                                            text=text_chunk,
                                            model_id="eleven_multilingual_v2"
                                        )
                                        audio_bytes = b"".join(audio_generator)
                                        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')

                                        # Envoyer l'audio encodÃ©
                                        audio_data = {'type': 'audio', 'content': audio_base64}
                                        yield f"data: {json.dumps(audio_data)}\n\n"
                                        print(f"âœ“ Audio envoyÃ© - base64: {len(audio_base64)} chars, audio brut: {len(audio_bytes)} bytes")
                                    except Exception as audio_error:
                                        print(f"âš ï¸ Erreur audio bloc: {audio_error}")
                                        import traceback
                                        traceback.print_exc()

                # Traiter les phrases restantes (buffer de phrases + texte en cours)
                remaining_text = []
                if sentence_buffer:
                    remaining_text.extend(sentence_buffer)
                if buffer.strip():
                    remaining_text.append(buffer.strip())

                if remaining_text:
                    final_text = ' '.join(remaining_text)
                    print(f"ğŸµ GÃ©nÃ©ration audio phrases finales: '{final_text[:60]}...'")
                    try:
                        audio_generator = elevenlabs_client.text_to_speech.convert(
                            voice_id=ELEVENLABS_VOICE_ID,
                            text=final_text,
                            model_id="eleven_multilingual_v2"
                        )
                        audio_bytes = b"".join(audio_generator)
                        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                        yield f"data: {json.dumps({'type': 'audio', 'content': audio_base64})}\n\n"
                    except Exception as audio_error:
                        print(f"âš ï¸ Erreur audio final: {audio_error}")

                # Signal de fin
                yield f"data: {json.dumps({'type': 'done'})}\n\n"
                print(f"âœ… Streaming terminÃ© - {sentence_count} phrases gÃ©nÃ©rÃ©es")

            except Exception as e:
                print(f"âŒ Erreur streaming: {e}")
                import traceback
                traceback.print_exc()
                yield f"data: {json.dumps({'type': 'error', 'content': str(e)})}\n\n"

        return app.response_class(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/speak_stream', methods=['POST'])
def text_to_speech_stream():
    """
    Streaming audio avec ElevenLabs - gÃ©nÃ¨re l'audio au fur et Ã  mesure.
    """
    try:
        data = request.json
        text = data.get('text', '')

        if not text:
            return jsonify({'error': 'Aucun texte fourni'}), 400

        print(f"ğŸ”Š Streaming audio pour: '{text[:50]}...'")

        # GÃ©nÃ©rer l'audio avec ElevenLabs en streaming
        audio_stream = elevenlabs_client.text_to_speech.convert(
            voice_id=ELEVENLABS_VOICE_ID,
            text=text,
            model_id="eleven_multilingual_v2",
            stream=True  # Activer le streaming
        )

        def generate_audio():
            """GÃ©nÃ©rateur pour streamer l'audio"""
            try:
                for chunk in audio_stream:
                    yield chunk
            except Exception as e:
                print(f"âŒ Erreur streaming audio: {e}")

        return app.response_class(
            generate_audio(),
            mimetype='audio/mpeg',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        print(f"âŒ Erreur de synthÃ¨se vocale: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/process', methods=['POST'])
def process_voice():
    """
    Endpoint tout-en-un: transcrit l'audio, traduit et gÃ©nÃ¨re la rÃ©ponse vocale.
    """
    try:
        # VÃ©rifier qu'un fichier audio a Ã©tÃ© envoyÃ©
        if 'audio' not in request.files:
            return jsonify({'error': 'Aucun fichier audio fourni'}), 400

        audio_file = request.files['audio']

        # 1. Transcrire l'audio
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:
            audio_file.save(temp_audio.name)
            temp_path = temp_audio.name

        with open(temp_path, 'rb') as audio:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio,
                language="fr"
            )

        os.unlink(temp_path)
        french_text = transcript.text
        print(f"ğŸ“ Transcription: {french_text}")

        # 2. Traduire le texte
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a professional translator. Translate the following French text to English. Only respond with the translation, nothing else."
                },
                {
                    "role": "user",
                    "content": french_text
                }
            ],
            temperature=0.3
        )

        translation = response.choices[0].message.content.strip()
        print(f"âœ… Traduction: '{translation}'")

        # 3. GÃ©nÃ©rer l'audio de la traduction
        audio_generator = elevenlabs_client.generate(
            text=translation,
            voice=ELEVENLABS_VOICE_ID,
            model="eleven_multilingual_v2"
        )

        audio_bytes = b"".join(audio_generator)

        return jsonify({
            'success': True,
            'transcription': french_text,
            'translation': translation,
            'audio_url': '/api/speak'  # Le frontend devra faire un second appel
        })

    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


if __name__ == '__main__':
    print("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                                â•‘")
    print("â•‘           ğŸ™ï¸  INTERFACE WEB VOCALE INTERACTIVE ğŸ™ï¸              â•‘")
    print("â•‘                                                                â•‘")
    print("â•‘  Serveur dÃ©marrÃ© sur http://localhost:5000                     â•‘")
    print("â•‘                                                                â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

    app.run(debug=True, host='0.0.0.0', port=5000)

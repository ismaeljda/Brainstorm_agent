"""
Application web Flask pour l'interface vocale interactive.
Permet de parler via le micro du navigateur et d'Ã©couter la rÃ©ponse.
"""

import os
import io
import tempfile
import requests
from flask import Flask, render_template, request, jsonify, send_file
from flask_cors import CORS
from dotenv import load_dotenv
from openai import OpenAI
from elevenlabs.client import ElevenLabs
import speech_recognition as sr
from pydub import AudioSegment

# Charger les variables d'environnement
load_dotenv("src/.env")

# Initialiser Flask
app = Flask(__name__)
CORS(app)

# Initialiser les clients
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
elevenlabs_client = ElevenLabs(api_key=os.getenv("ELEVENLABS_API_KEY"))
recognizer = sr.Recognizer()

# Configuration
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID", "21m00Tcm4TlvDq8ikWAM")

# Voix ElevenLabs pour les agents (basÃ© sur src/agents/prompts.py)
AGENT_VOICES = {
    'facilitateur': '21m00Tcm4TlvDq8ikWAM',  # Rachel - Professional female
    'strategie': 'pNInz6obpgDQGcFmaJgB',     # Adam - Articulate male
    'tech': 'TxGEqnHWrfWFTfGW9XjX',          # Josh - Clear male
    'creatif': 'EXAVITQu4vr4xnSDxMaL',      # Bella - Enthusiastic female
}


@app.route('/')
def index():
    """Page principale."""
    return render_template('index.html')


@app.route('/api/transcribe', methods=['POST'])
def transcribe_audio():
    """
    Transcrit l'audio envoyÃ© depuis le navigateur.
    Whisper accepte directement WebM, pas besoin de conversion.
    """
    temp_path = None

    try:
        # VÃ©rifier qu'un fichier audio a Ã©tÃ© envoyÃ©
        if 'audio' not in request.files:
            return jsonify({'error': 'Aucun fichier audio fourni'}), 400

        audio_file = request.files['audio']

        # Sauvegarder le fichier temporairement
        # Whisper API accepte plusieurs formats dont webm, mp3, mp4, mpeg, mpga, m4a, wav
        # Utiliser .wav car c'est ce que le frontend envoie aprÃ¨s conversion
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:
            audio_file.save(temp_audio.name)
            temp_path = temp_audio.name

        print(f"ğŸ“¦ Fichier reÃ§u: {os.path.getsize(temp_path)} bytes")

        # Transcrire avec Whisper (OpenAI)
        # Whisper accepte directement le format WebM
        print("ğŸ¤ Envoi Ã  Whisper...")
        with open(temp_path, 'rb') as audio_file_obj:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file_obj,
                language="fr"
            )

        text = transcript.text
        print(f"ğŸ“ Transcription: {text}")

        return jsonify({
            'success': True,
            'text': text
        })

    except Exception as e:
        print(f"âŒ Erreur de transcription: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

    finally:
        # Nettoyer le fichier temporaire
        if temp_path and os.path.exists(temp_path):
            os.unlink(temp_path)


@app.route('/api/chat', methods=['POST'])
def chat_with_agent():
    """
    Agent conversationnel simple - rÃ©pond en une seule fois (pas de streaming).
    """
    try:
        data = request.json
        user_message = data.get('text', '')
        conversation_history = data.get('history', [])

        if not user_message:
            return jsonify({'error': 'Aucun message fourni'}), 400

        print(f"ğŸ’¬ Message utilisateur: '{user_message}'")

        # Construire l'historique de conversation
        messages = [
            {
                "role": "system",
                "content": """Tu es un assistant de brainstorming intelligent et crÃ©atif.
Tu aides les consultants indÃ©pendants Ã  dÃ©velopper leurs idÃ©es de business.
Tu poses des questions pertinentes, proposes des idÃ©es innovantes et donnes des conseils stratÃ©giques.
RÃ©ponds toujours en franÃ§ais de maniÃ¨re claire, concise et professionnelle.
Sois enthousiaste et encourageant.
Fais des phrases courtes et claires."""
            }
        ]

        # Ajouter l'historique de conversation
        messages.extend(conversation_history)

        # Ajouter le nouveau message de l'utilisateur
        messages.append({
            "role": "user",
            "content": user_message
        })

        # GÃ©nÃ©rer la rÃ©ponse avec GPT (sans streaming)
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=200
        )

        agent_response = response.choices[0].message.content.strip()
        print(f"âœ… RÃ©ponse agent: '{agent_response}'")

        return jsonify({
            'success': True,
            'response': agent_response
        })

    except Exception as e:
        print(f"âŒ Erreur agent: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/chat_stream', methods=['POST'])
def chat_with_agent_stream():
    """
    Agent conversationnel avec streaming - gÃ©nÃ¨re et envoie le texte progressivement.
    """
    try:
        data = request.json
        user_message = data.get('text', '')
        conversation_history = data.get('history', [])

        if not user_message:
            return jsonify({'error': 'Aucun message fourni'}), 400

        print(f"ğŸ’¬ Message utilisateur: '{user_message}'")

        # Construire l'historique de conversation
        messages = [
            {
                "role": "system",
                "content": """Tu es un assistant de brainstorming intelligent et crÃ©atif.
Tu aides les consultants indÃ©pendants Ã  dÃ©velopper leurs idÃ©es de business.
Tu poses des questions pertinentes, proposes des idÃ©es innovantes et donnes des conseils stratÃ©giques.
RÃ©ponds toujours en franÃ§ais de maniÃ¨re claire, concise et professionnelle.
Sois enthousiaste et encourageant.
Fais des phrases courtes et claires."""
            }
        ]

        # Ajouter l'historique de conversation
        messages.extend(conversation_history)

        # Ajouter le nouveau message de l'utilisateur
        messages.append({
            "role": "user",
            "content": user_message
        })

        def generate():
            """GÃ©nÃ©rateur pour le streaming SSE (Server-Sent Events)"""
            try:
                # GÃ©nÃ©rer la rÃ©ponse avec GPT en streaming
                stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    temperature=0.7,
                    max_tokens=200,
                    stream=True  # Activer le streaming
                )

                full_response = ""
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        # Envoyer chaque morceau au client
                        yield f"data: {content}\n\n"

                # Envoyer le signal de fin
                yield "data: [DONE]\n\n"

                print(f"âœ… RÃ©ponse complÃ¨te: '{full_response}'")

            except Exception as e:
                print(f"âŒ Erreur streaming: {e}")
                yield f"data: [ERROR]: {str(e)}\n\n"

        return app.response_class(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        print(f"âŒ Erreur agent: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/speak', methods=['POST'])
def text_to_speech():
    """
    Convertit le texte en audio avec ElevenLabs et renvoie le fichier audio.
    Supporte les multi-voix pour le systÃ¨me d'agents.
    """
    try:
        data = request.json
        text = data.get('text', '')
        agent_id = data.get('agent', None)  # Optionnel: pour multi-agent

        if not text:
            return jsonify({'error': 'Aucun texte fourni'}), 400

        # Choisir la voix: agent spÃ©cifique ou voix par dÃ©faut
        if agent_id and agent_id in AGENT_VOICES:
            voice_id = AGENT_VOICES[agent_id]
            print(f"ğŸµ GÃ©nÃ©ration audio pour agent '{agent_id}': '{text[:50]}...'")
        else:
            voice_id = ELEVENLABS_VOICE_ID
            print(f"ğŸ”Š GÃ©nÃ©ration audio: '{text[:50]}...'")

        # GÃ©nÃ©rer l'audio avec ElevenLabs (nouvelle API)
        audio_generator = elevenlabs_client.text_to_speech.convert(
            voice_id=voice_id,
            text=text,
            model_id="eleven_multilingual_v2"
        )

        # Convertir en bytes
        audio_bytes = b"".join(audio_generator)

        # Retourner l'audio
        return send_file(
            io.BytesIO(audio_bytes),
            mimetype='audio/mpeg',
            as_attachment=False
        )

    except Exception as e:
        print(f"âŒ Erreur de synthÃ¨se vocale: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/chat_and_speak_stream', methods=['POST'])
def chat_and_speak_stream():
    """
    Streaming intelligent: GPT gÃ©nÃ¨re phrase par phrase, chaque phrase est convertie en audio.
    Format de sortie: Server-Sent Events avec texte ET audio encodÃ© en base64.
    """
    try:
        import json
        import base64
        import re

        data = request.json
        user_message = data.get('text', '')
        conversation_history = data.get('history', [])

        if not user_message:
            return jsonify({'error': 'Aucun message fourni'}), 400

        print(f"ğŸ’¬ Message utilisateur: '{user_message}'")

        # Construire l'historique de conversation
        messages = [
            {
                "role": "system",
                "content": """Tu es un assistant de brainstorming intelligent et crÃ©atif.
Tu aides les consultants indÃ©pendants Ã  dÃ©velopper leurs idÃ©es de business.
Tu poses des questions pertinentes, proposes des idÃ©es innovantes et donnes des conseils stratÃ©giques.
RÃ©ponds toujours en franÃ§ais de maniÃ¨re claire, concise et professionnelle.
Sois enthousiaste et encourageant.
Fais des phrases courtes et claires."""
            }
        ]
        messages.extend(conversation_history)
        messages.append({"role": "user", "content": user_message})

        def generate():
            """GÃ©nÃ©rateur qui stream texte + audio phrase par phrase"""
            try:
                # Streamer GPT
                stream = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    temperature=0.7,
                    max_tokens=200,
                    stream=True
                )

                buffer = ""
                sentence_buffer = []  # Buffer pour accumuler des phrases
                sentence_count = 0
                SENTENCES_PER_CHUNK = 2  # Envoyer par blocs de 2 phrases (plus rÃ©actif)

                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        buffer += content

                        # Envoyer le texte immÃ©diatement pour l'affichage
                        yield f"data: {json.dumps({'type': 'text', 'content': content})}\n\n"

                        # DÃ©tecter les fins de phrases (plus flexible avec ponctuation)
                        sentences = re.split(r'([.!?]+\s*)', buffer)

                        # Si on a au moins une phrase complÃ¨te
                        if len(sentences) > 2:
                            # RÃ©cupÃ©rer toutes les phrases complÃ¨tes
                            complete_sentences = ''.join(sentences[:-1])
                            buffer = sentences[-1]  # Garder le reste dans le buffer

                            if complete_sentences.strip():
                                sentence_buffer.append(complete_sentences.strip())
                                sentence_count += 1

                                print(f"âœ… Phrase #{sentence_count} dÃ©tectÃ©e: '{complete_sentences.strip()[:50]}...'")

                                # Envoyer l'audio par blocs de 2 phrases OU immÃ©diatement si dÃ©jÃ  beaucoup de texte
                                if len(sentence_buffer) >= SENTENCES_PER_CHUNK:
                                    text_chunk = ' '.join(sentence_buffer)
                                    sentence_buffer = []  # Vider le buffer

                                    print(f"ğŸµ GÃ©nÃ©ration audio ({len(sentence_buffer) + SENTENCES_PER_CHUNK} phrases): '{text_chunk[:60]}...'")

                                    # GÃ©nÃ©rer l'audio pour ce bloc SANS ATTENDRE
                                    try:
                                        audio_generator = elevenlabs_client.text_to_speech.convert(
                                            voice_id=ELEVENLABS_VOICE_ID,
                                            text=text_chunk,
                                            model_id="eleven_multilingual_v2"
                                        )
                                        audio_bytes = b"".join(audio_generator)
                                        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')

                                        # Envoyer l'audio encodÃ©
                                        audio_data = {'type': 'audio', 'content': audio_base64}
                                        yield f"data: {json.dumps(audio_data)}\n\n"
                                        print(f"âœ“ Audio envoyÃ© - base64: {len(audio_base64)} chars, audio brut: {len(audio_bytes)} bytes")
                                    except Exception as audio_error:
                                        print(f"âš ï¸ Erreur audio bloc: {audio_error}")
                                        import traceback
                                        traceback.print_exc()

                # Traiter les phrases restantes (buffer de phrases + texte en cours)
                remaining_text = []
                if sentence_buffer:
                    remaining_text.extend(sentence_buffer)
                if buffer.strip():
                    remaining_text.append(buffer.strip())

                if remaining_text:
                    final_text = ' '.join(remaining_text)
                    print(f"ğŸµ GÃ©nÃ©ration audio phrases finales: '{final_text[:60]}...'")
                    try:
                        audio_generator = elevenlabs_client.text_to_speech.convert(
                            voice_id=ELEVENLABS_VOICE_ID,
                            text=final_text,
                            model_id="eleven_multilingual_v2"
                        )
                        audio_bytes = b"".join(audio_generator)
                        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                        yield f"data: {json.dumps({'type': 'audio', 'content': audio_base64})}\n\n"
                    except Exception as audio_error:
                        print(f"âš ï¸ Erreur audio final: {audio_error}")

                # Signal de fin
                yield f"data: {json.dumps({'type': 'done'})}\n\n"
                print(f"âœ… Streaming terminÃ© - {sentence_count} phrases gÃ©nÃ©rÃ©es")

            except Exception as e:
                print(f"âŒ Erreur streaming: {e}")
                import traceback
                traceback.print_exc()
                yield f"data: {json.dumps({'type': 'error', 'content': str(e)})}\n\n"

        return app.response_class(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/speak_stream', methods=['POST'])
def text_to_speech_stream():
    """
    Streaming audio avec ElevenLabs - gÃ©nÃ¨re l'audio au fur et Ã  mesure.
    """
    try:
        data = request.json
        text = data.get('text', '')

        if not text:
            return jsonify({'error': 'Aucun texte fourni'}), 400

        print(f"ğŸ”Š Streaming audio pour: '{text[:50]}...'")

        # GÃ©nÃ©rer l'audio avec ElevenLabs en streaming
        audio_stream = elevenlabs_client.text_to_speech.convert(
            voice_id=ELEVENLABS_VOICE_ID,
            text=text,
            model_id="eleven_multilingual_v2",
            stream=True  # Activer le streaming
        )

        def generate_audio():
            """GÃ©nÃ©rateur pour streamer l'audio"""
            try:
                for chunk in audio_stream:
                    yield chunk
            except Exception as e:
                print(f"âŒ Erreur streaming audio: {e}")

        return app.response_class(
            generate_audio(),
            mimetype='audio/mpeg',
            headers={
                'Cache-Control': 'no-cache',
                'X-Accel-Buffering': 'no'
            }
        )

    except Exception as e:
        print(f"âŒ Erreur de synthÃ¨se vocale: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/process', methods=['POST'])
def process_voice():
    """
    Endpoint tout-en-un: transcrit l'audio, traduit et gÃ©nÃ¨re la rÃ©ponse vocale.
    """
    try:
        # VÃ©rifier qu'un fichier audio a Ã©tÃ© envoyÃ©
        if 'audio' not in request.files:
            return jsonify({'error': 'Aucun fichier audio fourni'}), 400

        audio_file = request.files['audio']

        # 1. Transcrire l'audio
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:
            audio_file.save(temp_audio.name)
            temp_path = temp_audio.name

        with open(temp_path, 'rb') as audio:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio,
                language="fr"
            )

        os.unlink(temp_path)
        french_text = transcript.text
        print(f"ğŸ“ Transcription: {french_text}")

        # 2. Traduire le texte
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a professional translator. Translate the following French text to English. Only respond with the translation, nothing else."
                },
                {
                    "role": "user",
                    "content": french_text
                }
            ],
            temperature=0.3
        )

        translation = response.choices[0].message.content.strip()
        print(f"âœ… Traduction: '{translation}'")

        # 3. GÃ©nÃ©rer l'audio de la traduction
        audio_generator = elevenlabs_client.generate(
            text=translation,
            voice=ELEVENLABS_VOICE_ID,
            model="eleven_multilingual_v2"
        )

        audio_bytes = b"".join(audio_generator)

        return jsonify({
            'success': True,
            'transcription': french_text,
            'translation': translation,
            'audio_url': '/api/speak'  # Le frontend devra faire un second appel
        })

    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/token', methods=['GET'])
def get_realtime_token():
    """
    GÃ©nÃ¨re un token Ã©phÃ©mÃ¨re pour l'API OpenAI Realtime.
    Permet au frontend de se connecter au WebSocket OpenAI sans exposer la clÃ© API.
    """
    try:
        print("ğŸ”‘ GÃ©nÃ©ration token OpenAI Realtime API...")

        response = requests.post(
            'https://api.openai.com/v1/realtime/sessions',
            headers={
                'Authorization': f'Bearer {os.getenv("OPENAI_API_KEY")}',
                'Content-Type': 'application/json'
            },
            json={
                'model': 'gpt-4o-realtime-preview-2024-12-17',
                'voice': 'alloy'
            }
        )

        if response.status_code != 200:
            print(f"âŒ Erreur API OpenAI: {response.status_code}")
            return jsonify({'error': 'Failed to generate token'}), 500

        data = response.json()
        print(f"âœ… Token gÃ©nÃ©rÃ©")

        return jsonify({
            'token': data['client_secret']['value'],
            'expires_at': data['client_secret']['expires_at']
        })

    except Exception as e:
        print(f"âŒ Erreur gÃ©nÃ©ration token: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/meeting')
def meeting_room():
    """Interface de meeting room multi-agents avec voix."""
    return render_template('meeting_room_agents.html')


@app.route('/api/agents_config', methods=['GET'])
def get_agents_config():
    """
    Retourne la configuration des agents depuis src/agents/prompts.py
    pour alimenter l'orchestrateur OpenAI Realtime.
    """
    try:
        # Charger les prompts depuis src/agents/prompts.py
        import sys
        sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))
        from agents.prompts import AGENTS_PROMPTS

        # Construire le prompt d'orchestrateur avec les vraies personnalitÃ©s
        orchestrator_prompt = """Tu es un ORCHESTRATEUR de meeting intelligent qui anime une DISCUSSION ENTRE AGENTS. PARLE EN FRANÃ‡AIS.

ğŸ¯ FLUX DE CONVERSATION:
1. L'utilisateur lance un sujet â†’ Le Facilitateur pose UNE question Ã  un agent spÃ©cifique
2. L'agent interrogÃ© rÃ©pond (2 phrases max)
3. Le Facilitateur enchaÃ®ne avec une question Ã  UN AUTRE agent
4. Les agents se rÃ©pondent et construisent ensemble la solution

ğŸ“‹ RÃˆGLES D'ORCHESTRATION:
- Alterne entre les agents pour crÃ©er une vraie conversation
- Le Facilitateur lance TOUJOURS les questions, jamais les rÃ©ponses longues
- Chaque agent doit intervenir selon son expertise
- CrÃ©e un flow naturel: question â†’ rÃ©ponse â†’ nouvelle question â†’ rÃ©ponse...

RÃˆGLE ABSOLUE:
- Commence TOUJOURS par: [AGENT: nom]
- Exemples: "[AGENT: facilitateur] ...", "[AGENT: strategie] ...", "[AGENT: tech] ...", "[AGENT: creatif] ..."
- Respecte EXACTEMENT les rÃ¨gles de chaque agent (nombre de phrases, style, etc.)

AGENTS DISPONIBLES:

--- FACILITATEUR ---
""" + AGENTS_PROMPTS['facilitateur'] + """

--- STRATÃˆGE BUSINESS ---
""" + AGENTS_PROMPTS['strategie'] + """

--- TECH LEAD ---
""" + AGENTS_PROMPTS['tech'] + """

--- CRÃ‰ATIF ---
""" + AGENTS_PROMPTS['creatif'] + """

ğŸ’¡ EXEMPLE DE FLOW:
User: "Je veux crÃ©er une app de gestion de projet"
â†’ [AGENT: facilitateur] StratÃ¨ge : c'est quoi le marchÃ© cible ?
â†’ [AGENT: strategie] Cible : PME 10-50 employÃ©s. ModÃ¨le freemium + abonnement Ã©quipes.
â†’ [AGENT: facilitateur] Tech Lead : faisable en combien de temps ?
â†’ [AGENT: tech] Faisable. MVP : 2-3 mois avec stack simple.
â†’ [AGENT: facilitateur] CrÃ©atif : comment se diffÃ©rencier ?
â†’ [AGENT: creatif] Interface type Slack avec threads. Simple tech, fort impact UX.

IMPORTANT: Fais parler les agents entre eux pour construire la solution ensemble!"""

        return jsonify({
            'orchestrator_prompt': orchestrator_prompt,
            'agents': {
                'facilitateur': {'name': 'Facilitateur', 'voice': 'facilitateur'},
                'strategie': {'name': 'StratÃ¨ge Business', 'voice': 'strategie'},
                'tech': {'name': 'Tech Lead', 'voice': 'tech'},
                'creatif': {'name': 'Creative Thinker', 'voice': 'creatif'}
            }
        })

    except Exception as e:
        print(f"âŒ Erreur chargement config agents: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    print("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                                â•‘")
    print("â•‘           ğŸ™ï¸  INTERFACE WEB VOCALE INTERACTIVE ğŸ™ï¸              â•‘")
    print("â•‘                                                                â•‘")
    print("â•‘  Serveur dÃ©marrÃ© sur http://localhost:5000                     â•‘")
    print("â•‘  Meeting Room: http://localhost:5000/meeting                   â•‘")
    print("â•‘                                                                â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

    app.run(debug=True, host='0.0.0.0', port=5000)
